import torch
import torch.nn as nn
from PIL import Image
import torchvision.transforms as T
import argparse
import os
import torchvision # save_imageë¥¼ ìœ„í•´ ì¶”ê°€

# re_model.pyì—ì„œ ëª¨ë¸ ìƒì„± í•¨ìˆ˜ ì„í¬íŠ¸
from re_model import create_model 

def load_trained_model(checkpoint_path, device, encoder_name="resnet34"):
    """í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    print(f"=> '{encoder_name}' ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ ìƒì„± ì¤‘...")
    model = create_model(device=device, encoder_name=encoder_name)
    
    if not os.path.exists(checkpoint_path):
        print(f"ì˜¤ë¥˜: ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ '{checkpoint_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì—†ìŒ: {checkpoint_path}")
        
    print(f"=> ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°: '{checkpoint_path}'")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    if "gen_state_dict" in checkpoint: # Pix2Pix GAN ì²´í¬í¬ì¸íŠ¸ì˜ ê²½ìš° ìƒì„±ì ê°€ì¤‘ì¹˜ ë¡œë“œ
        model.load_state_dict(checkpoint["gen_state_dict"])
        print("Pix2Pix ìƒì„±ì(Generator) ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    elif "state_dict" in checkpoint: # ì¼ë°˜ U-Net ì²´í¬í¬ì¸íŠ¸ì˜ ê²½ìš°
        model.load_state_dict(checkpoint["state_dict"])
        print("ì¼ë°˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    else:
        # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ëª¨ë¸ì˜ state_dict ìì²´ì¼ ê²½ìš°
        model.load_state_dict(checkpoint)
        print("ëª¨ë¸ state_dict ìì²´ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        
    model.eval() 
    print("ëª¨ë¸ ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ. ì¶”ë¡  ëª¨ë“œë¡œ ì„¤ì •ë¨.")
    return model

def preprocess_image(image_path, image_size=256):
    """ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ë§ê²Œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        img = Image.open(image_path).convert("RGB")
    except FileNotFoundError:
        print(f"ì˜¤ë¥˜: ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ '{image_path}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    except Exception as e:
        print(f"ì˜¤ë¥˜: ì…ë ¥ ì´ë¯¸ì§€ '{image_path}' ë¡œë“œ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
        return None

    transform = T.Compose([
        T.Resize((image_size, image_size)),
        T.ToTensor(),
        T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) 
    ])
    img_tensor = transform(img)
    return img_tensor.unsqueeze(0) 

def postprocess_and_save_image(pred_tensor, output_path):
    """ì˜ˆì¸¡ëœ í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    if pred_tensor.dim() == 4 and pred_tensor.size(0) == 1:
        pred_tensor = pred_tensor.squeeze(0) 
    if pred_tensor.dim() == 3 and pred_tensor.size(0) == 1:
        pred_tensor = pred_tensor.squeeze(0)

    # [-1, 1] -> [0, 1] ë²”ìœ„ë¡œ ë³€í™˜ (ë§Œì•½ ì•„ì§ ì•ˆë˜ì–´ ìˆë‹¤ë©´)
    # ëª¨ë¸ ì¶œë ¥ì´ ì´ë¯¸ [0,1]ì´ê±°ë‚˜ ë‹¤ë¥¸ ë²”ìœ„ë¼ë©´ ì´ ë¶€ë¶„ì€ ì¡°ì ˆ í•„ìš”
    # í˜„ì¬ëŠ” ëª¨ë¸ ì¶œë ¥ì´ [-1,1]ì´ë¼ê³  ê°€ì •í•˜ê³  LPIPS/ì¼ë°˜ í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
    pred_tensor_normalized_for_save = (pred_tensor * 0.5) + 0.5
    pred_tensor_normalized_for_save = torch.clamp(pred_tensor_normalized_for_save, 0, 1)
    
    try:
        torchvision.utils.save_image(pred_tensor_normalized_for_save.cpu(), output_path)
        print(f"ì˜ˆì¸¡ëœ í•˜ì´íŠ¸ë§µ ì €ì¥ ì™„ë£Œ: '{output_path}'")
    except Exception as e:
        print(f"ì˜¤ë¥˜: ì˜ˆì¸¡ ì´ë¯¸ì§€ ì €ì¥ ì¤‘ ë¬¸ì œ ë°œìƒ ({output_path}): {e}")

def predict(args):
    DEVICE = "cuda" if torch.cuda.is_available() and args.use_gpu else "cpu"
    print(f"ì¶”ë¡  ì¥ì¹˜: {DEVICE}")

    # 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    try:
        model = load_trained_model(args.checkpoint_path, DEVICE, args.encoder)
    except Exception as e: # FileNotFoundError í¬í•¨í•˜ì—¬ ëª¨ë“  ì˜ˆì™¸ ì²˜ë¦¬
        print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 2. ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    # ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œê°€ ì‹¤ì œ íŒŒì¼ì¸ì§€ í™•ì¸
    if not os.path.exists(args.input_image_path):
        print(f"ì˜¤ë¥˜: ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ '{args.input_image_path}'ê°€ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. --input_image_pathë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì„ì‹œ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ì„ íƒ ì‚¬í•­)
        # print("ì„ì‹œ ë”ë¯¸ ì…ë ¥ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤ (ê²°ê³¼ëŠ” ì˜ë¯¸ ì—†ì„ ìˆ˜ ìˆìŒ).")
        # temp_img = Image.new('RGB', (args.image_size, args.image_size), color = 'red')
        # temp_img_path = "temp_dummy_input.png"
        # temp_img.save(temp_img_path)
        # input_tensor = preprocess_image(temp_img_path, args.image_size)
        # os.remove(temp_img_path)
        return # ë˜ëŠ” ì—¬ê¸°ì„œ ì¢…ë£Œ
    else:
        input_tensor = preprocess_image(args.input_image_path, args.image_size)

    if input_tensor is None:
        return 
    input_tensor = input_tensor.to(DEVICE)

    # 3. ì¶”ë¡  ì‹¤í–‰
    print(f"ì…ë ¥ ì´ë¯¸ì§€ë¡œ ì¶”ë¡  ì‹œì‘: '{args.input_image_path}'")
    with torch.no_grad(): 
        prediction_tensor = model(input_tensor)
    print("ì¶”ë¡  ì™„ë£Œ.")

    # 4. ê²°ê³¼ í›„ì²˜ë¦¬ ë° ì €ì¥
    output_dir = os.path.dirname(args.output_image_path)
    if output_dir and not os.path.exists(output_dir):
        try:
            os.makedirs(output_dir, exist_ok=True)
            print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: '{output_dir}'")
        except OSError as e:
            print(f"ì˜¤ë¥˜: ì¶œë ¥ ë””ë ‰í† ë¦¬ '{output_dir}' ìƒì„± ì‹¤íŒ¨: {e}")
            print(f"ê²°ê³¼ë¥¼ í˜„ì¬ ë””ë ‰í† ë¦¬ì— '{os.path.basename(args.output_image_path)}' ì´ë¦„ìœ¼ë¡œ ì €ì¥ ì‹œë„í•©ë‹ˆë‹¤.")
            args.output_image_path = os.path.basename(args.output_image_path)
            
    postprocess_and_save_image(prediction_tensor, args.output_image_path)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="í•™ìŠµëœ ëª¨ë¸ë¡œ í•˜ì´íŠ¸ë§µ ì¶”ë¡ ")
    
    # --- ê²½ë¡œ ê´€ë ¨ ì¸ì ---
    # ì‚¬ìš©ìê°€ ì´ ê¸°ë³¸ê°’ë“¤ì„ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•´ì•¼ í•¨ì„ ëª…ì‹œ
    parser.add_argument("--checkpoint_path", type=str, 
                        default="training_outputs/efb7_lr1e-4_bs40_lpips_0/checkpoints/checkpoint_epoch_1000.pth.tar", # ğŸ‘ˆ ì‚¬ìš©ìê°€ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•´ì•¼ í•¨
                        help="í•™ìŠµëœ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: checkpoints/epoch_100.pth.tar)")
    parser.add_argument("--input_image_path", type=str, 
                        default="IOFiles/Input/input_Dotpaper.png", # ğŸ‘ˆ ì‚¬ìš©ìê°€ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•´ì•¼ í•¨
                        help="ì…ë ¥ ì¬ì§ˆ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: test_images/fabric.png)")
    parser.add_argument("--output_image_path", type=str, 
                        default="IOFiles/Output/output_Dotpaper_1000.png", # ğŸ‘ˆ ì‚¬ìš©ìê°€ ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½í•´ì•¼ í•¨
                        help="ì˜ˆì¸¡ëœ í•˜ì´íŠ¸ë§µì„ ì €ì¥í•  ê²½ë¡œ (ê¸°ë³¸ê°’: í˜„ì¬ í´ë”ì˜ predicted_heightmap.png)")
    
    # --- ëª¨ë¸ ë° ì¶”ë¡  ì„¤ì • ê´€ë ¨ ì¸ì ---
    parser.add_argument("--encoder", type=str, default="efficientnet-b7", 
                        help="í•™ìŠµ ì‹œ ì‚¬ìš©í•œ U-Netì˜ ì¸ì½”ë” ì´ë¦„ (ê¸°ë³¸ê°’: resnet34)")
    parser.add_argument("--image_size", type=int, default=256, 
                        help="í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í¬ê¸° (ê¸°ë³¸ê°’: 256)")
    parser.add_argument("--use_gpu", action='store_true', default=False,
                        help="GPUë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡  (í”Œë˜ê·¸ ì§€ì • ì‹œ True, ê¸°ë³¸ê°’: False, ì¦‰ CPU ì‚¬ìš©)")
    
    args = parser.parse_args()


    predict(args)